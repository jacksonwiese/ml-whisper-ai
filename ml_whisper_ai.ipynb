{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOc7wFE/OfputqzfDcEUl8C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonwiese/ml-whisper-ai/blob/main/ml_whisper_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u3SyjYIn255",
        "outputId": "2ba6ca8c-ffbe-419a-ad8d-1b3be0b03c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-923blrlj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-923blrlj\n",
            "  Resolved https://github.com/openai/whisper.git to commit c09a7ae299c4c34c5839a76380ae407e7d785914\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0+cu118)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.11.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798038 sha256=8e7fb8682298b2df240b94a92dfd1569de0929506f5a9f1c06fc86c1bf489c5d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vypefn_u/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg #allows us to work with audio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"audioFile.m4a\" --model medium.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdoSM1Ino1hm",
        "outputId": "2c704bfc-25e5-4620-c56d-14b74c02eb0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:05<00:00, 263MiB/s]\n",
            "[00:00.000 --> 00:07.320]  It's a service that doesn't give us the owner's information, so it allows you to like start alerts with your information\n",
            "[00:07.320 --> 00:10.860]  Okay, and so they get sent to the owner and then they will contact you. Okay\n",
            "[00:10.860 --> 00:16.000]  Here's all his, the pet's information, and if you want to look up the microchip number yourself\n",
            "[00:16.000 --> 00:21.160]  And then here, if you feel comfortable giving this information, I can start the alert for you\n",
            "[00:24.680 --> 00:26.680]  Ah, it's a boy\n",
            "[00:26.680 --> 00:28.680]  The male golden\n",
            "[00:31.000 --> 00:33.000]  Frankie\n",
            "[00:40.360 --> 00:42.360]  You said Frankie, right?\n",
            "[00:53.280 --> 00:55.600]  So like hypothetically, but it's docked on Facebook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YH6jwk-psmV",
        "outputId": "cf84a92f-4342-421c-c57f-31194201987a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: whisper\n",
            "       [-h]\n",
            "       [--model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}]\n",
            "       [--model_dir MODEL_DIR]\n",
            "       [--device DEVICE]\n",
            "       [--output_dir OUTPUT_DIR]\n",
            "       [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "       [--verbose VERBOSE]\n",
            "       [--task {transcribe,translate}]\n",
            "       [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "       [--temperature TEMPERATURE]\n",
            "       [--best_of BEST_OF]\n",
            "       [--beam_size BEAM_SIZE]\n",
            "       [--patience PATIENCE]\n",
            "       [--length_penalty LENGTH_PENALTY]\n",
            "       [--suppress_tokens SUPPRESS_TOKENS]\n",
            "       [--initial_prompt INITIAL_PROMPT]\n",
            "       [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
            "       [--fp16 FP16]\n",
            "       [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "       [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "       [--logprob_threshold LOGPROB_THRESHOLD]\n",
            "       [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "       [--word_timestamps WORD_TIMESTAMPS]\n",
            "       [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "       [--append_punctuations APPEND_PUNCTUATIONS]\n",
            "       [--highlight_words HIGHLIGHT_WORDS]\n",
            "       [--max_line_width MAX_LINE_WIDTH]\n",
            "       [--max_line_count MAX_LINE_COUNT]\n",
            "       [--threads THREADS]\n",
            "       audio\n",
            "       [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio\n",
            "    audio\n",
            "    file(s) to\n",
            "    transcribe\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}\n",
            "    name of the\n",
            "    Whisper\n",
            "    model to\n",
            "    use\n",
            "    (default:\n",
            "    small)\n",
            "  --model_dir MODEL_DIR\n",
            "    the path to\n",
            "    save model\n",
            "    files; uses\n",
            "    ~/.cache/wh\n",
            "    isper by\n",
            "    default\n",
            "    (default:\n",
            "    None)\n",
            "  --device DEVICE\n",
            "    device to\n",
            "    use for\n",
            "    PyTorch\n",
            "    inference\n",
            "    (default:\n",
            "    cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "    directory\n",
            "    to save the\n",
            "    outputs\n",
            "    (default:\n",
            "    .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "    format of\n",
            "    the output\n",
            "    file; if\n",
            "    not\n",
            "    specified,\n",
            "    all\n",
            "    available\n",
            "    formats\n",
            "    will be\n",
            "    produced\n",
            "    (default:\n",
            "    all)\n",
            "  --verbose VERBOSE\n",
            "    whether to\n",
            "    print out\n",
            "    the\n",
            "    progress\n",
            "    and debug\n",
            "    messages\n",
            "    (default:\n",
            "    True)\n",
            "  --task {transcribe,translate}\n",
            "    whether to\n",
            "    perform\n",
            "    X->X speech\n",
            "    recognition\n",
            "    ('transcrib\n",
            "    e') or\n",
            "    X->English\n",
            "    translation\n",
            "    ('translate\n",
            "    ')\n",
            "    (default:\n",
            "    transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "    language\n",
            "    spoken in\n",
            "    the audio,\n",
            "    specify\n",
            "    None to\n",
            "    perform\n",
            "    language\n",
            "    detection\n",
            "    (default:\n",
            "    None)\n",
            "  --temperature TEMPERATURE\n",
            "    temperature\n",
            "    to use for\n",
            "    sampling\n",
            "    (default:\n",
            "    0)\n",
            "  --best_of BEST_OF\n",
            "    number of\n",
            "    candidates\n",
            "    when\n",
            "    sampling\n",
            "    with non-\n",
            "    zero\n",
            "    temperature\n",
            "    (default:\n",
            "    5)\n",
            "  --beam_size BEAM_SIZE\n",
            "    number of\n",
            "    beams in\n",
            "    beam\n",
            "    search,\n",
            "    only\n",
            "    applicable\n",
            "    when\n",
            "    temperature\n",
            "    is zero\n",
            "    (default:\n",
            "    5)\n",
            "  --patience PATIENCE\n",
            "    optional\n",
            "    patience\n",
            "    value to\n",
            "    use in beam\n",
            "    decoding,\n",
            "    as in https\n",
            "    ://arxiv.or\n",
            "    g/abs/2204.\n",
            "    05424, the\n",
            "    default\n",
            "    (1.0) is\n",
            "    equivalent\n",
            "    to conventi\n",
            "    onal beam\n",
            "    search\n",
            "    (default:\n",
            "    None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "    optional\n",
            "    token\n",
            "    length\n",
            "    penalty\n",
            "    coefficient\n",
            "    (alpha) as\n",
            "    in https://\n",
            "    arxiv.org/a\n",
            "    bs/1609.081\n",
            "    44, uses\n",
            "    simple\n",
            "    length norm\n",
            "    alization\n",
            "    by default\n",
            "    (default:\n",
            "    None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "    comma-\n",
            "    separated\n",
            "    list of\n",
            "    token ids\n",
            "    to suppress\n",
            "    during\n",
            "    sampling;\n",
            "    '-1' will\n",
            "    suppress\n",
            "    most\n",
            "    special\n",
            "    characters\n",
            "    except\n",
            "    common punc\n",
            "    tuations\n",
            "    (default:\n",
            "    -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "    optional\n",
            "    text to\n",
            "    provide as\n",
            "    a prompt\n",
            "    for the\n",
            "    first\n",
            "    window.\n",
            "    (default:\n",
            "    None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "    if True,\n",
            "    provide the\n",
            "    previous\n",
            "    output of\n",
            "    the model\n",
            "    as a prompt\n",
            "    for the\n",
            "    next\n",
            "    window;\n",
            "    disabling\n",
            "    may make\n",
            "    the text in\n",
            "    consistent\n",
            "    across\n",
            "    windows,\n",
            "    but the\n",
            "    model\n",
            "    becomes\n",
            "    less prone\n",
            "    to getting\n",
            "    stuck in a\n",
            "    failure\n",
            "    loop\n",
            "    (default:\n",
            "    True)\n",
            "  --fp16 FP16\n",
            "    whether to\n",
            "    perform\n",
            "    inference\n",
            "    in fp16;\n",
            "    True by\n",
            "    default\n",
            "    (default:\n",
            "    True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "    temperature\n",
            "    to increase\n",
            "    when\n",
            "    falling\n",
            "    back when\n",
            "    the\n",
            "    decoding\n",
            "    fails to\n",
            "    meet either\n",
            "    of the\n",
            "    thresholds\n",
            "    below\n",
            "    (default:\n",
            "    0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "    if the gzip\n",
            "    compression\n",
            "    ratio is\n",
            "    higher than\n",
            "    this value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "    if the\n",
            "    average log\n",
            "    probability\n",
            "    is lower\n",
            "    than this\n",
            "    value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "    if the\n",
            "    probability\n",
            "    of the <|no\n",
            "    speech|>\n",
            "    token is\n",
            "    higher than\n",
            "    this value\n",
            "    AND the\n",
            "    decoding\n",
            "    has failed\n",
            "    due to `log\n",
            "    prob_thresh\n",
            "    old`,\n",
            "    consider\n",
            "    the segment\n",
            "    as silence\n",
            "    (default:\n",
            "    0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "    (experiment\n",
            "    al) extract\n",
            "    word-level\n",
            "    timestamps\n",
            "    and refine\n",
            "    the results\n",
            "    based on\n",
            "    them\n",
            "    (default:\n",
            "    False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    next word\n",
            "    (default:\n",
            "    \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    previous\n",
            "    word\n",
            "    (default: \"\n",
            "    '.。,，!！?？:：\n",
            "    ”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    underline\n",
            "    each word\n",
            "    as it is\n",
            "    spoken in\n",
            "    srt and vtt\n",
            "    (default:\n",
            "    False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    characters\n",
            "    in a line\n",
            "    before\n",
            "    breaking\n",
            "    the line\n",
            "    (default:\n",
            "    None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    lines in a\n",
            "    segment\n",
            "    (default:\n",
            "    None)\n",
            "  --threads THREADS\n",
            "    number of\n",
            "    threads\n",
            "    used by\n",
            "    torch for\n",
            "    CPU\n",
            "    inference;\n",
            "    supercedes \n",
            "    MKL_NUM_THR\n",
            "    EADS/OMP_NU\n",
            "    M_THREADS\n",
            "    (default:\n",
            "    0)\n"
          ]
        }
      ]
    }
  ]
}